{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to Develop Convolutional Neural Networks for Multi-Step Time Series Forecasting](https://machinelearningmastery.com/how-to-develop-convolutional-neural-networks-for-multi-step-time-series-forecasting/)\n",
    "-------------------\n",
    "Unlike other machine learning algorithms, convolutional neural networks are capable of automatically learning features from sequence data, support multiple-variate data, and can directly output a vector for multi-step forecasting. As such, one-dimensional CNNs have been demonstrated to perform well and even achieve state-of-the-art results on challenging sequence prediction problems.\n",
    "\n",
    "In this tutorial, you will discover how to develop 1D convolutional neural networks for multi-step time series forecasting.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "- How to develop a CNN for multi-step time series forecasting model for univariate data.\n",
    "- How to develop a multichannel multi-step time series forecasting model for multivariate data.\n",
    "- How to develop a multi-headed multi-step time series forecasting model for multivariate data.\n",
    "\n",
    "# Tutorial Overview\n",
    "\n",
    "1. Problem Description\n",
    "2. Load and Prepare Dataset\n",
    "3. Model Evaluation\n",
    "4. CNNs for Multi-Step Forecasting\n",
    "5. Multi-step Time Series Forecasting With a Univariate CNN\n",
    "6. Multi-step Time Series Forecasting With a Multichannel CNN\n",
    "7. Multi-step Time Series Forecasting With a Multihead CNN\n",
    "\n",
    "# 1 Problem Description\n",
    "The '[Household Power Consumption](https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption)' dataset is a multivariate time series dataset that describes the electricity consumption for a single household over four years.\n",
    "\n",
    "The data was collected between December 2006 and November 2010 and observations of power consumption within the household were collected every minute.\n",
    "\n",
    "It is a multivariate series comprised of seven variables (besides the date and time); they are:\n",
    "variable | Description\n",
    "--- | ---\n",
    "global_active_power   | The total active power consumed by the household (kilowatts).\n",
    "global_reactive_power | The total reactive power consumed by the household (kilowatts).\n",
    "voltage               | Average voltage (volts).\n",
    "global_intensity      | Average current intensity (amps).\n",
    "sub_metering_1        | Active energy for kitchen (watt-hours of active energy).\n",
    "sub_metering_2        | Active energy for laundry (watt-hours of active energy).\n",
    "sub_metering_3        | Active energy for climate control systems (watt-hours of active energy).\n",
    "\n",
    "Active and reactive energy refer to the technical details of alternative current.\n",
    "\n",
    "A fourth sub-metering variable can be created by subtracting the sum of three defined sub-metering variables from the total active energy as follows:\n",
    "···python\n",
    "sub_metering_remainder = (global_active_power * 1000 / 60) - (sub_metering_1 + sub_metering_2 + sub_metering_3)\n",
    "···\n",
    "\n",
    "# 2 Load and Prepare Dataset\n",
    "The dataset can be downloaded from the UCI Machine Learning repository as a single 20 megabyte .zip file:\n",
    "\n",
    "- [household_power_consumption.zip](https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip)\n",
    "\n",
    "Download the dataset and unzip it into your current working directory. You will now have the file \"*household_power_consumption.txt*\" that is about 127 megabytes in size and contains all of the observations.\n",
    "\n",
    "We can use the **read_csv()** function to load the data and combine the first two columns into a single date-time column that we can use as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:29:00</th>\n",
       "      <td>3.520</td>\n",
       "      <td>0.522</td>\n",
       "      <td>235.020</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:30:00</th>\n",
       "      <td>3.702</td>\n",
       "      <td>0.520</td>\n",
       "      <td>235.090</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:31:00</th>\n",
       "      <td>3.700</td>\n",
       "      <td>0.520</td>\n",
       "      <td>235.220</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:32:00</th>\n",
       "      <td>3.668</td>\n",
       "      <td>0.510</td>\n",
       "      <td>233.990</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:33:00</th>\n",
       "      <td>3.662</td>\n",
       "      <td>0.510</td>\n",
       "      <td>233.860</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Global_active_power Global_reactive_power  Voltage  \\\n",
       "datetime                                                                 \n",
       "2006-12-16 17:24:00               4.216                 0.418  234.840   \n",
       "2006-12-16 17:25:00               5.360                 0.436  233.630   \n",
       "2006-12-16 17:26:00               5.374                 0.498  233.290   \n",
       "2006-12-16 17:27:00               5.388                 0.502  233.740   \n",
       "2006-12-16 17:28:00               3.666                 0.528  235.680   \n",
       "2006-12-16 17:29:00               3.520                 0.522  235.020   \n",
       "2006-12-16 17:30:00               3.702                 0.520  235.090   \n",
       "2006-12-16 17:31:00               3.700                 0.520  235.220   \n",
       "2006-12-16 17:32:00               3.668                 0.510  233.990   \n",
       "2006-12-16 17:33:00               3.662                 0.510  233.860   \n",
       "\n",
       "                    Global_intensity Sub_metering_1 Sub_metering_2  \\\n",
       "datetime                                                             \n",
       "2006-12-16 17:24:00           18.400          0.000          1.000   \n",
       "2006-12-16 17:25:00           23.000          0.000          1.000   \n",
       "2006-12-16 17:26:00           23.000          0.000          2.000   \n",
       "2006-12-16 17:27:00           23.000          0.000          1.000   \n",
       "2006-12-16 17:28:00           15.800          0.000          1.000   \n",
       "2006-12-16 17:29:00           15.000          0.000          2.000   \n",
       "2006-12-16 17:30:00           15.800          0.000          1.000   \n",
       "2006-12-16 17:31:00           15.800          0.000          1.000   \n",
       "2006-12-16 17:32:00           15.800          0.000          1.000   \n",
       "2006-12-16 17:33:00           15.800          0.000          2.000   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "datetime                             \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  \n",
       "2006-12-16 17:29:00            17.0  \n",
       "2006-12-16 17:30:00            17.0  \n",
       "2006-12-16 17:31:00            17.0  \n",
       "2006-12-16 17:32:00            17.0  \n",
       "2006-12-16 17:33:00            16.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and clean-up data\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from pandas import to_numeric\n",
    "# load all data\n",
    "dataset = read_csv('./input/household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can mark all [missing values](https://machinelearningmastery.com/handle-missing-timesteps-sequence-prediction-problems-python/) indicated with a ‘?‘ character with a NaN value, which is a float.\n",
    "\n",
    "This will allow us to work with the data as one array of floating point values rather than mixed types (less efficient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark all missing values\n",
    "dataset.replace('?', nan, inplace=True)\n",
    "# make dataset numeric\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to fill in the missing values now that they have been marked.\n",
    "\n",
    "A very simple approach would be to copy the observation from the same time the day before. We can implement this in a function named **fill_missing()** that will take the NumPy array of the data and copy values from exactly 24 hours ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with a value at the same time one day ago\n",
    "def fill_missing(values):\n",
    "    one_day = 60 * 24\n",
    "    for row in range(values.shape[0]):\n",
    "        for col in range(values.shape[1]):\n",
    "            if isnan(values[row, col]):\n",
    "                values[row, col] = values[row - one_day, col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this function directly to the data within the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing\n",
    "fill_missing(dataset.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new column that contains the remainder of the sub-metering, using the calculation from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column for for the remainder of sub metering\n",
    "values = dataset.values\n",
    "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the cleaned-up version of the dataset to a new file; in this case we will just change the file extension to .csv and save the dataset as '*household_power_consumption.csv*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated dataset\n",
    "dataset.to_csv('./input/household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model Evaluation\n",
    "\n",
    "In this section, we will consider how we can develop and evaluate predictive models for the household power dataset.\n",
    "\n",
    "This section is divided into four parts; they are:\n",
    "1. Problem Framing\n",
    "2. Evaluation Metric\n",
    "3. Train and Test Sets\n",
    "4. Walk-Forward Validation\n",
    "\n",
    "## Problem Framing\n",
    "\n",
    "There are many ways to harness and explore the household power consumption dataset.\n",
    "\n",
    "In this tutorial, we will use the data to explore a very specific question; that is:\n",
    "> Given recent power consumption, what is the expected power consumption for the week ahead?\n",
    "\n",
    "This requires that a predictive model forecast the total active power for each day over the next seven days.\n",
    "\n",
    "Technically, this framing of the problem is referred to as a multi-step time series forecasting problem, given the multiple forecast steps. A model that makes use of multiple input variables may be referred to as a multivariate multi-step time series forecasting model.\n",
    "\n",
    "A model of this type could be helpful within the household in planning expenditures. It could also be helpful on the supply side for planning electricity demand for a specific household.\n",
    "\n",
    "This framing of the dataset also suggests that it would be useful to downsample the per-minute observations of power consumption to daily totals. This is not required, but makes sense, given that we are interested in total power per day.\n",
    "\n",
    "We can achieve this easily using the [**resample()**](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) function on the pandas DataFrame. Calling this function with the argument '*D*' allows the loaded data indexed by date-time to be grouped by day ([ee all offset aliases](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases)). We can then calculate the sum of all observations for each day and create a new dataset of daily power consumption data for each of the eight variables.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 8)\n",
      "            Global_active_power  Global_reactive_power    Voltage  \\\n",
      "datetime                                                            \n",
      "2006-12-16             1209.176                 34.922   93552.53   \n",
      "2006-12-17             3390.460                226.006  345725.32   \n",
      "2006-12-18             2203.826                161.792  347373.64   \n",
      "2006-12-19             1666.194                150.942  348479.01   \n",
      "2006-12-20             2225.748                160.998  348923.61   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
      "datetime                                                                       \n",
      "2006-12-16            5180.8             0.0           546.0          4926.0   \n",
      "2006-12-17           14398.6          2033.0          4187.0         13341.0   \n",
      "2006-12-18            9247.2          1063.0          2621.0         14018.0   \n",
      "2006-12-19            7094.0           839.0          7602.0          6197.0   \n",
      "2006-12-20            9313.0             0.0          2648.0         14063.0   \n",
      "\n",
      "            sub_metering_4  \n",
      "datetime                    \n",
      "2006-12-16    14680.933319  \n",
      "2006-12-17    36946.666732  \n",
      "2006-12-18    19028.433281  \n",
      "2006-12-19    13131.900043  \n",
      "2006-12-20    20384.800011  \n"
     ]
    }
   ],
   "source": [
    "# resample minute data to total for each day\n",
    "# from pandas import read_csv\n",
    "# load the new file\n",
    "dataset = read_csv('./input/household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('./input/household_power_consumption_days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a new daily total power consumption dataset and saves the result into a separate file named `household_power_consumption_days.csv`.\n",
    "\n",
    "We can use this as the dataset for fitting and evaluating predictive models for the chosen framing of the problem.\n",
    "\n",
    "## Evaluation Metric\n",
    "\n",
    "A forecast will be comprised of seven values, one for each day of the week ahead.\n",
    "\n",
    "It is common with multi-step forecasting problems to evaluate each forecasted time step separately. This is helpful for a few reasons:\n",
    "- To comment on the skill at a specific lead time (e.g. +1 day vs +3 days).\n",
    "- To contrast models based on their skills at different lead times (e.g. models good at +1 day vs models good at days +5).\n",
    "\n",
    "The units of the total power are kilowatts and it would be useful to have an error metric that was also in the same units. Both Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) fit this bill, although RMSE is more commonly used and will be adopted in this tutorial. Unlike MAE, RMSE is more punishing of forecast errors.\n",
    "\n",
    "The performance metric for this problem will be the RMSE for each lead time from day 1 to day 7.\n",
    "\n",
    "As a short-cut, it may be useful to summarize the performance of a model using a single score in order to aide in model selection.\n",
    "\n",
    "One possible score that could be used would be the RMSE across all forecast days.\n",
    "\n",
    "The function evaluate_forecasts() below will implement this behavior and return the performance of a model based on multiple seven-day forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
